{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training from Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import click\n",
    "import math\n",
    "from collections import deque\n",
    "from copy import copy\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(0, '../src/streamspot')\n",
    "\n",
    "from iostream import *\n",
    "from graph import *\n",
    "from streamhash import *\n",
    "from cluster import *\n",
    "import utils as U\n",
    "import param as P\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = '../baseline/sbustreamspot-data/all.tsv'\n",
    "bootstrap = '../baseline/streamspot-bootstrap-clusters/01-C50_k10_all.txt'\n",
    "chunk_length = 50\n",
    "num_parallel_graphs = 10\n",
    "max_num_edges = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par = int(num_parallel_graphs)\n",
    "\n",
    "clusters, cluster_thresholds, global_threshold = read_bootstrap_clusters(bootstrap)\n",
    "cluster_sizes = []\n",
    "train_gids = set()\n",
    "cluster_map = {}\n",
    "\n",
    "statistics = []\n",
    "\n",
    "for i, cluster in clusters.items():\n",
    "    cluster_sizes.append(len(cluster))\n",
    "    for g in cluster:\n",
    "        train_gids.add(g)\n",
    "        cluster_map[g] = i\n",
    "\n",
    "logging.debug(f\"Training Graphs: {train_gids}\")\n",
    "\n",
    "test_gids, train_edges, test_edges, num_test_edges = read_edges(edges, train_gids)\n",
    "random.shuffle(test_gids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = U.allocate_random_bits(chunk_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_graph = {}\n",
    "\n",
    "for gid, edges in test_edges.items():\n",
    "#     print(e[:10])\n",
    "    logging.debug(f'updating test graph {gid}')\n",
    "    for e in edges:\n",
    "        update_graphs(e, test_graph)\n",
    "test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Construct static test Shingles\n",
    "test_streamhash_sketches = {}\n",
    "test_streamhash_projections = {}\n",
    "for gid in train_gids:\n",
    "    logging.info(f\" {gid}\")\n",
    "    temp_shingle_vector = construct_temp_shingle_vector(test_graph[gid],\n",
    "                                                        chunk_length)\n",
    "    \n",
    "    test_streamhash_sketches[gid], test_streamhash_projections[gid] \\\n",
    "        = construct_streamhash_sketch(temp_shingle_vector, H)\n",
    "    \n",
    "    logging.debug(f\"Sketch for test graph {gid}: {test_streamhash_sketches[gid]}\")\n",
    "#     logging.debug(f\"Projection for test graph {gid}: {test_streamhash_projections[gid]}\")\n",
    "\n",
    "with open('test_graph_sketches.json', 'w') as fout:\n",
    "    fout.write(json.dumps(test_streamhash_sketches))\n",
    "with open('test_graph_projections.json', 'w') as fout:\n",
    "    fout.write(json.dumps(test_streamhash_projections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('centroid_sketches.json', 'r') as fin:\n",
    "    centroid_sketches = json.loads(fin.read())\n",
    "\n",
    "with open('test_graph_sketches.json', 'r') as fin:\n",
    "    test_sketches = json.loads(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroid_sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_sketches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_sketches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_anomaly_scores(centroid_sketches, test_sketches):\n",
    "    test_anomaly_scores = {}\n",
    "    for gid in test_sketches.keys():\n",
    "        logging.debug(gid)\n",
    "        test_anomaly_scores[gid] = []\n",
    "        for i in centroid_sketches.keys():\n",
    "            dist = 1.0 - math.cos(\n",
    "                P.PI * (1.0 - streamhash_similarity(test_sketches[gid],\n",
    "                                                    centroid_sketches[i]))\n",
    "            )\n",
    "            test_anomaly_scores[gid].append(dist)\n",
    "    \n",
    "    return test_anomaly_scores\n",
    "\n",
    "anomaly_scores = get_anomaly_scores(centroid_sketches, test_sketches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_scores = pd.DataFrame([(k, min(v)) for k, v in anomaly_scores.items()], columns=['gid', 'anomaly_score'])\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores['y_true'] = test_scores['gid'].apply(lambda x: int(x.startswith('3')))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_scores.y_true, test_scores.anomaly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Cpp Code Eval with gfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = pd.read_csv('../data/test_anomaly_scores_cpp.txt', names=['scores'])\n",
    "\n",
    "anomaly_scores = anomaly_scores.reset_index()\n",
    "anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = anomaly_scores[anomaly_scores['scores']!=-2]\n",
    "test_scores['y_true'] = test_scores['index'].apply(lambda x: int(x>=300 and x<=399))\n",
    "\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(test_scores, x='scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_scores.y_true, test_scores.scores)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(test_scores.y_true, test_scores.scores)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr,\n",
    "    y=tpr,\n",
    "    name='ROC'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0.0,1.0],\n",
    "    y=[0.0,1.0],\n",
    "    name='',\n",
    "    line = dict(color='gray', width=4, dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"ROC (AUC = {auc})\",\n",
    "    xaxis_title=\"FPR\",\n",
    "    yaxis_title=\"TPR\",\n",
    "    legend_title=\"Legend Title\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
